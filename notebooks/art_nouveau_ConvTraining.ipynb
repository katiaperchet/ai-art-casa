{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Set Kaggle API information and dataset local directories",
   "id": "b41c419b4e0c3cc3"
  },
  {
   "cell_type": "code",
   "id": "b112b4b4-b7c6-425a-b60c-348c1b3f5ffc",
   "metadata": {},
   "source": [
    "# Set Kaggle API - Username / Key\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"franconicolsmerenda\"\n",
    "os.environ['KAGGLE_KEY'] = \"edcd91fb1521ad3ee181a8b093795eab\"\n",
    "os.environ['DATASET_FOLDER'] = \"/home/millenium-falcon/SoftwareProjects/ai-art-casa/.datasets\"\n",
    "os.environ['ART_STYLE'] = \"art_nouveau\"\n",
    "\n",
    "# DATASET Folders\n",
    "os.environ['TRAIN_DATASET_ART_STYLE'] = f\"{os.environ['DATASET_FOLDER']}/Real_AI_SD_LD_Dataset/train\"\n",
    "os.environ['TEST_DATASET_ART_STYLE'] = f\"{os.environ['DATASET_FOLDER']}/Real_AI_SD_LD_Dataset/test\"\n",
    "\n",
    "# Data to be consumed by the model!\n",
    "os.environ['TOP_DIR']=f\"{os.environ['DATASET_FOLDER']}/{os.environ['ART_STYLE']}\"\n",
    "os.environ['TRAIN_ART_STYLE_DATA'] = f\"{os.environ['DATASET_FOLDER']}/{os.environ['ART_STYLE']}/train\"\n",
    "os.environ['VALID_ART_STYLE_DATA'] = f\"{os.environ['DATASET_FOLDER']}/{os.environ['ART_STYLE']}/valid\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Download dataset if it is not stored locally",
   "id": "1a199f15fa7159e8"
  },
  {
   "cell_type": "code",
   "id": "85e50d4c-4c2c-4205-8a77-4d6bd474d870",
   "metadata": {},
   "source": [
    "# Download Datasets if Needed\n",
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = f\"{os.environ['DATASET_FOLDER']}\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(f\"{folder_path}/Real_AI_SD_LD_Dataset\"):\n",
    "    # Install kaggle package\n",
    "    !pip install -q kaggle\n",
    "    # Download the dataset from Kaggle\n",
    "    !kaggle datasets download -d ravidussilva/real-ai-art -p $folder_path --unzip\n",
    "else:\n",
    "    print(\"Folder already exists.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Copy and divide images into directories separating them by the requested Art Style",
   "id": "d57891cff5cc55fb"
  },
  {
   "cell_type": "code",
   "id": "0b1ff207-e37a-437d-9429-23651922008c",
   "metadata": {},
   "source": [
    "# Set Art Style Dataset\n",
    "\n",
    "# 1. Make clean data\n",
    "!rm -rf $TRAIN_ART_STYLE_DATA\n",
    "!rm -rf $VALID_ART_STYLE_DATA\n",
    "\n",
    "# 2. Create folders of the current art style training/validation data\n",
    "!mkdir -p $TRAIN_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!mkdir -p $TRAIN_ART_STYLE_DATA/$ART_STYLE\n",
    "\n",
    "!mkdir -p $VALID_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!mkdir -p $VALID_ART_STYLE_DATA/$ART_STYLE\n",
    "\n",
    "# 3. Load with data from DATASET\n",
    "!cp -r $TRAIN_DATASET_ART_STYLE/AI_LD_$ART_STYLE/*.jpg $TRAIN_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TRAIN_DATASET_ART_STYLE/AI_SD_$ART_STYLE/*.jpg $TRAIN_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TRAIN_DATASET_ART_STYLE/$ART_STYLE/*.jpg $TRAIN_ART_STYLE_DATA/$ART_STYLE\n",
    "\n",
    "!cp -r $TEST_DATASET_ART_STYLE/AI_LD_$ART_STYLE/*.jpg $VALID_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TEST_DATASET_ART_STYLE/AI_SD_$ART_STYLE/*.jpg $VALID_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TEST_DATASET_ART_STYLE/$ART_STYLE/*.jpg $VALID_ART_STYLE_DATA/$ART_STYLE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Import the needed dependencies for the model and data visualization",
   "id": "fb16af0587abe1e6"
  },
  {
   "cell_type": "code",
   "id": "3fc81345-1e48-4b60-be2c-0b89781333cf",
   "metadata": {},
   "source": [
    "#Import Dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.layers import Rescaling, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import regularizers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Set dataset parameters and details",
   "id": "6522d1e064cec5f9"
  },
  {
   "cell_type": "code",
   "id": "faa8a89a-aed3-42bd-ada6-05d510ffab21",
   "metadata": {},
   "source": [
    "# Define paths to training and validation data\n",
    "train_data_dir = os.environ['TRAIN_ART_STYLE_DATA']\n",
    "valid_data_dir = os.environ['VALID_ART_STYLE_DATA']\n",
    "\n",
    "# Define constants\n",
    "IMG_WIDTH, IMG_HEIGHT = 32,32\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 30"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Define the directory path for training dataset",
   "id": "bd901b33eed35149"
  },
  {
   "cell_type": "code",
   "id": "90f01546-6134-45aa-ad3b-97b6150016d9",
   "metadata": {},
   "source": [
    "top_dir = os.environ['TOP_DIR']\n",
    "\n",
    "# Define the training paths\n",
    "train_dir = os.path.join(top_dir, 'train')\n",
    "\n",
    "# List all directories in the train directory\n",
    "all_directories = os.listdir(train_dir)\n",
    "\n",
    "# Initialize lists to store directories for human-drawn and AI-generated images\n",
    "train_human = []\n",
    "train_ai = []\n",
    "\n",
    "# Loop through all directories\n",
    "for directory in all_directories:\n",
    "    # Check if the directory represents human-drawn images\n",
    "    if not directory.startswith('AI_'):\n",
    "        train_human.append(os.path.join(train_dir, directory))\n",
    "    # Check if the directory represents AI-generated images\n",
    "    else:\n",
    "        train_ai.append(os.path.join(train_dir, directory))\n",
    "\n",
    "# Print the lists of directories\n",
    "print(\"Train directories containing human-drawn images:\")\n",
    "for i, directory in enumerate(train_human):\n",
    "    print(f\"{i}. {directory}\")\n",
    "\n",
    "print(\"\\nTrain directories containing AI-generated images:\")\n",
    "for i, directory in enumerate(train_ai):\n",
    "    print(f\"{i}. {directory}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Define the directory path for validation dataset",
   "id": "759dc4a638d4c6d9"
  },
  {
   "cell_type": "code",
   "id": "a1158c2a-8eab-489e-9419-2c25c2d9a5d4",
   "metadata": {},
   "source": [
    "# Define the test paths\n",
    "test_dir = os.path.join(top_dir, 'valid')\n",
    "\n",
    "# List all directories in the test directory\n",
    "all_directories = os.listdir(test_dir)\n",
    "\n",
    "# Initialize lists to store directories for human-drawn and AI-generated images\n",
    "test_human = []\n",
    "test_ai = []\n",
    "\n",
    "# Loop through all directories\n",
    "for directory in all_directories:\n",
    "    # Check if the directory represents human-drawn images\n",
    "    if not directory.startswith('AI_'):\n",
    "        test_human.append(os.path.join(test_dir, directory))\n",
    "    # Check if the directory represents AI-generated images\n",
    "    else:\n",
    "        test_ai.append(os.path.join(test_dir, directory))\n",
    "\n",
    "# Print the lists of directories\n",
    "print(\"Test directories containing human-drawn images:\")\n",
    "for i, directory in enumerate(test_human):\n",
    "    print(f\"{i}. {directory}\")\n",
    "\n",
    "print(\"\\nTest directories containing AI-generated images:\")\n",
    "for i, directory in enumerate(test_ai):\n",
    "    print(f\"{i}. {directory}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Data preprocessing- Labeling training data.",
   "id": "142d853da143dd58"
  },
  {
   "cell_type": "code",
   "id": "46d14a2b-fcef-43bf-a886-98b6bbc8a58e",
   "metadata": {},
   "source": [
    "# Initialize lists to store file paths and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "# Initialize an empty DataFrame for train_data\n",
    "train_data = pd.DataFrame(columns=['filepath', 'label'])\n",
    "\n",
    "# Label files under train_human as \"human\"\n",
    "for directory in train_human:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"human\")\n",
    "\n",
    "# Label files under train_ai as \"AI\"\n",
    "for directory in train_ai:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"AI\")\n",
    "\n",
    "# Create a DataFrame with file paths and labels\n",
    "data = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Concatenate data with train_data\n",
    "train_data = pd.concat([train_data, data], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Display the amount of images for training dataset",
   "id": "18cfcd35491a36b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Count the number of files under each label\n",
    "file_counts = train_data['label'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of files under each label:\")\n",
    "print(file_counts)"
   ],
   "id": "5a2da561dc6692f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Data preprocessing- Labeling validation data.",
   "id": "3e453b131267fd11"
  },
  {
   "cell_type": "code",
   "id": "6425fb35-b893-4a6d-b31f-a47be98037ef",
   "metadata": {},
   "source": [
    "# Initialize lists to store file paths and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "# Initialize an empty DataFrame for test_data\n",
    "test_data = pd.DataFrame(columns=['filepath', 'label'])\n",
    "\n",
    "# Label files under test_human as \"human\"\n",
    "for directory in test_human:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"human\")\n",
    "\n",
    "# Label files under test_ai as \"AI\"\n",
    "for directory in test_ai:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"AI\")\n",
    "\n",
    "# Create a DataFrame with file paths and labels\n",
    "data = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Concatenate data with test_data\n",
    "test_data = pd.concat([test_data, data], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. Display the amount of images for validation dataset",
   "id": "93f2cc83bdac4f2a"
  },
  {
   "cell_type": "code",
   "id": "f904c8f3-11b6-4c35-8233-a64a7e82dcc7",
   "metadata": {},
   "source": [
    "# Display the first few rows of the test_data DataFrame\n",
    "print(test_data.head())\n",
    "\n",
    "# Count the number of files under each label\n",
    "file_counts = test_data['label'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"\\nNumber of files under each label:\")\n",
    "print(file_counts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12. Data preprocessing- Adding data augmentation and creating training dataset. ",
   "id": "190a6a4fb9a2786e"
  },
  {
   "cell_type": "code",
   "id": "7a8c277e-fb79-4547-8d94-c1a53e9184b8",
   "metadata": {},
   "source": [
    "training_generator = ImageDataGenerator(rescale=1./255,  # to normalize pixel value\n",
    "                                        rotation_range=7, # it will apply rotations to the image\n",
    "                                       horizontal_flip=True # it will flip image horizontally\n",
    "                                       )\n",
    "train_dataset = training_generator.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col='filepath',  # Column containing file paths\n",
    "    y_col='label',     # Column containing labels\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',  \n",
    "    shuffle=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 13. Data preprocessing- Adding data augmentation and creating validation dataset. ",
   "id": "393a122dff87329d"
  },
  {
   "cell_type": "code",
   "id": "17ded983-049a-4a4e-834b-f3368daa9de0",
   "metadata": {},
   "source": [
    "val_generator = ImageDataGenerator(rescale=1./255,            # Normalize the image pixel values to the range [0, 1] by scaling by 1/255\n",
    "    rotation_range=7,         # Randomly rotate images by up to 7 degrees\n",
    "    horizontal_flip=True)      # Randomly flip images horizontally\n",
    "val_dataset = val_generator.flow_from_dataframe(dataframe=test_data,\n",
    "                                                x_col='filepath',  # Column containing file paths\n",
    "                                                y_col='label',  # Column containing labels\n",
    "                                                target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                batch_size = 1,  # 1 image at a time to evaluate the NN\n",
    "                                                class_mode = 'binary',\n",
    "                                                shuffle = False\n",
    "                                                )   # to associate the prediction with expected output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 14. Defining CNN model and show its summary.",
   "id": "11aad4f2a228fa25"
  },
  {
   "cell_type": "code",
   "id": "97bac3de-e382-48a1-8604-bd1a5401f32d",
   "metadata": {},
   "source": [
    "#Build the model\n",
    "model = Sequential()\n",
    "#Adding Convolutional layer with 512 filters and relu activation function. \n",
    "model.add(Conv2D(filters = 512, kernel_size = 3, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "#Adding Max Pooling Layer\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "#Adding Convolutional layer with 128 filters and relu activation function. \n",
    "model.add(Conv2D(filters = 128, kernel_size = 3, activation='relu'))\n",
    "#Adding Max Pooling Layer\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "#Adding Convolutional layer with 32 filters and relu activation function. \n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "#Adding a Flatten layer to reduce the final model's matrix to a 1D matrix\n",
    "model.add(Flatten())\n",
    "#Added 3 full connected layers to have a final result. \n",
    "model.add(Dense(units =32, activation='relu'))\n",
    "model.add(Dense(units =16, activation='relu'))\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n",
    "#Show the model's summary. \n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15. Compile the model",
   "id": "678141eeff4a7b74"
  },
  {
   "cell_type": "code",
   "id": "dd13ebe0-530e-45b6-a91b-f8936f1f8899",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Add EarlyStopping with a patience of 5 to avoid overfitting. \n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 16. Train the model :)",
   "id": "f9bb8cd8e3546452"
  },
  {
   "cell_type": "code",
   "id": "b91dbdc0-164e-4ee5-8883-d2329d3d0c95",
   "metadata": {},
   "source": [
    "#TRAINING MODEL\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=val_dataset, callbacks=[es])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 17. Plotting the accuracy and loss functions of the epochs",
   "id": "3cd575abe15a5862"
  },
  {
   "cell_type": "code",
   "id": "23630c1a-941e-4fc2-8e38-4fdbd6f6d85f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Accuracy vs Loss\n",
    "# Plotting accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 18. Evaluate the trained model",
   "id": "b98cd0d60473adb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_loss, test_acc = model.evaluate(val_dataset)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(f'Test loss: {test_loss}')"
   ],
   "id": "d9a1f53fdb4411de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 19. Make predictions with the trained model",
   "id": "3afa47ef8e2a38c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get the true labels\n",
    "true_labels = val_dataset.classes\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(val_dataset)\n",
    "predicted_labels = np.round(predictions).flatten()  # For binary classification"
   ],
   "id": "579d33cc05accb1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 20. Generate F1 Score",
   "id": "36044847a1d5ab0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_prob = predictions\n",
    "y_pred = np.where(y_pred_prob > 0.5, 1, 0)\n",
    "# Calculate F1 score\n",
    "print(classification_report(true_labels, y_pred, target_names=val_dataset.class_indices.keys()))\n",
    "f1 = f1_score(true_labels, y_pred)\n",
    "print(f'F1 Score: {f1}')"
   ],
   "id": "63d8403e94b1eb2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 21. Generate the confusion matrix to validate results and plot the information",
   "id": "cc0e7a46a802bdae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['AI', 'human'], yticklabels=['AI', 'human'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "994d1fc2b05ecfc8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
