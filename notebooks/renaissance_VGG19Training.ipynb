{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Set Kaggle API information and dataset local directories",
   "id": "4080d77c5d433944"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b112b4b4-b7c6-425a-b60c-348c1b3f5ffc",
   "metadata": {},
   "source": [
    "# Set Kaggle API - Username / Key\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"franconicolsmerenda\"\n",
    "os.environ['KAGGLE_KEY'] = \"edcd91fb1521ad3ee181a8b093795eab\"\n",
    "os.environ['DATASET_FOLDER'] = \"/home/millenium-falcon/SoftwareProjects/ai-art-casa/.datasets\" #change this directory to the one where the data is\n",
    "os.environ['ART_STYLE'] = \"renaissance\"\n",
    "\n",
    "# DATASET Folders\n",
    "os.environ['TRAIN_DATASET_ART_STYLE'] = f\"{os.environ['DATASET_FOLDER']}/Real_AI_SD_LD_Dataset/train\"\n",
    "os.environ['TEST_DATASET_ART_STYLE'] = f\"{os.environ['DATASET_FOLDER']}/Real_AI_SD_LD_Dataset/test\"\n",
    "\n",
    "# Data to be consumed by the model!\n",
    "os.environ['TOP_DIR']=f\"{os.environ['DATASET_FOLDER']}/{os.environ['ART_STYLE']}\"\n",
    "os.environ['TRAIN_ART_STYLE_DATA'] = f\"{os.environ['DATASET_FOLDER']}/{os.environ['ART_STYLE']}/train\"\n",
    "os.environ['VALID_ART_STYLE_DATA'] = f\"{os.environ['DATASET_FOLDER']}/{os.environ['ART_STYLE']}/valid\""
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Download dataset if it is not stored locally",
   "id": "6723ec5554a2209"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e50d4c-4c2c-4205-8a77-4d6bd474d870",
   "metadata": {},
   "source": [
    "# Download Datasets if Needed\n",
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = f\"{os.environ['DATASET_FOLDER']}\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(f\"{folder_path}/Real_AI_SD_LD_Dataset\"):\n",
    "    # Install kaggle package\n",
    "    !pip install -q kaggle\n",
    "    # Download the dataset from Kaggle\n",
    "    !kaggle datasets download -d ravidussilva/real-ai-art -p $folder_path --unzip\n",
    "else:\n",
    "    print(\"Folder already exists.\")"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Copy and divide images into directories separating them by the requested Art Style",
   "id": "257d068a93425a6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1ff207-e37a-437d-9429-23651922008c",
   "metadata": {},
   "source": [
    "# Set Art Style Dataset\n",
    "\n",
    "# 1. Make clean data\n",
    "!rm -rf $TRAIN_ART_STYLE_DATA\n",
    "!rm -rf $VALID_ART_STYLE_DATA\n",
    "\n",
    "# 2. Create folders of the current art style training/validation data\n",
    "!mkdir -p $TRAIN_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!mkdir -p $TRAIN_ART_STYLE_DATA/$ART_STYLE\n",
    "\n",
    "!mkdir -p $VALID_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!mkdir -p $VALID_ART_STYLE_DATA/$ART_STYLE\n",
    "\n",
    "# 3. Load with data from DATASET\n",
    "!cp -r $TRAIN_DATASET_ART_STYLE/AI_LD_$ART_STYLE/*.jpg $TRAIN_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TRAIN_DATASET_ART_STYLE/AI_SD_$ART_STYLE/*.jpg $TRAIN_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TRAIN_DATASET_ART_STYLE/$ART_STYLE/*.jpg $TRAIN_ART_STYLE_DATA/$ART_STYLE\n",
    "\n",
    "!cp -r $TEST_DATASET_ART_STYLE/AI_LD_$ART_STYLE/*.jpg $VALID_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TEST_DATASET_ART_STYLE/AI_SD_$ART_STYLE/*.jpg $VALID_ART_STYLE_DATA/AI_GENERATED_$ART_STYLE\n",
    "!cp -r $TEST_DATASET_ART_STYLE/$ART_STYLE/*.jpg $VALID_ART_STYLE_DATA/$ART_STYLE"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Import the needed dependencies for the model and data visualization",
   "id": "df42aa0aebc3d9d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc81345-1e48-4b60-be2c-0b89781333cf",
   "metadata": {},
   "source": [
    "#Import Dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Rescaling,  MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Set dataset parameters and details",
   "id": "a937c11e31ca823b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa8a89a-aed3-42bd-ada6-05d510ffab21",
   "metadata": {},
   "source": [
    "# Define paths to training and validation data\n",
    "train_data_dir = os.environ['TRAIN_ART_STYLE_DATA']\n",
    "valid_data_dir = os.environ['VALID_ART_STYLE_DATA']\n",
    "\n",
    "# Define constants\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 30"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Define the directory path for training dataset",
   "id": "2fda39000b26490c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f01546-6134-45aa-ad3b-97b6150016d9",
   "metadata": {},
   "source": [
    "#Main directory where datasets are stored\n",
    "top_dir = os.environ['TOP_DIR']\n",
    "\n",
    "# Define the training paths\n",
    "train_dir = os.path.join(top_dir, 'train')\n",
    "\n",
    "# List all directories in the train directory\n",
    "all_directories = os.listdir(train_dir)\n",
    "\n",
    "# Initialize lists to store directories for human-drawn and AI-generated images\n",
    "train_human = []\n",
    "train_ai = []\n",
    "\n",
    "# Loop through all directories\n",
    "for directory in all_directories:\n",
    "    # Check if the directory represents human-drawn images\n",
    "    if not directory.startswith('AI_'):\n",
    "        train_human.append(os.path.join(train_dir, directory))\n",
    "    # Check if the directory represents AI-generated images\n",
    "    else:\n",
    "        train_ai.append(os.path.join(train_dir, directory))\n",
    "\n",
    "# Print the lists of directories\n",
    "print(\"Train directories containing human-drawn images:\")\n",
    "for i, directory in enumerate(train_human):\n",
    "    print(f\"{i}. {directory}\")\n",
    "\n",
    "print(\"\\nTrain directories containing AI-generated images:\")\n",
    "for i, directory in enumerate(train_ai):\n",
    "    print(f\"{i}. {directory}\")"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Define the directory path for validation dataset",
   "id": "4786d14fe4078849"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1158c2a-8eab-489e-9419-2c25c2d9a5d4",
   "metadata": {},
   "source": [
    "# Define the test paths\n",
    "test_dir = os.path.join(top_dir, 'valid')\n",
    "\n",
    "# List all directories in the test directory\n",
    "all_directories = os.listdir(test_dir)\n",
    "\n",
    "# Initialize lists to store directories for human-drawn and AI-generated images\n",
    "test_human = []\n",
    "test_ai = []\n",
    "\n",
    "# Loop through all directories\n",
    "for directory in all_directories:\n",
    "    # Check if the directory represents human-drawn images\n",
    "    if not directory.startswith('AI_'):\n",
    "        test_human.append(os.path.join(test_dir, directory))\n",
    "    # Check if the directory represents AI-generated images\n",
    "    else:\n",
    "        test_ai.append(os.path.join(test_dir, directory))\n",
    "\n",
    "# Print the lists of directories\n",
    "print(\"Test directories containing human-drawn images:\")\n",
    "for i, directory in enumerate(test_human):\n",
    "    print(f\"{i}. {directory}\")\n",
    "\n",
    "print(\"\\nTest directories containing AI-generated images:\")\n",
    "for i, directory in enumerate(test_ai):\n",
    "    print(f\"{i}. {directory}\")"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Data preprocessing- Labeling training data. ",
   "id": "5c58926f869bc2a9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d14a2b-fcef-43bf-a886-98b6bbc8a58e",
   "metadata": {},
   "source": [
    "# Initialize lists to store file paths and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "# Initialize an empty DataFrame for train_data with the columns filepath and label\n",
    "train_data = pd.DataFrame(columns=['filepath', 'label'])\n",
    "\n",
    "# Label files under train_human as \"human\"\n",
    "for directory in train_human:\n",
    "    for file in os.listdir(directory):\n",
    "        #creating value to store in filepath column\n",
    "        filepath = os.path.join(directory, file)\n",
    "        #append value into the column filepath\n",
    "        filepaths.append(filepath)\n",
    "        #adding classification 'human' to value\n",
    "        labels.append(\"human\")\n",
    "\n",
    "# Label files under train_ai as \"AI\"\n",
    "for directory in train_ai:\n",
    "    for file in os.listdir(directory):\n",
    "        #creating value to store in filepath column\n",
    "        filepath = os.path.join(directory, file)\n",
    "        #append value into the column filepath\n",
    "        filepaths.append(filepath)\n",
    "        #adding classification 'AI' to value\n",
    "        labels.append(\"AI\")\n",
    "\n",
    "# Create a DataFrame with file paths and labels\n",
    "data = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Concatenate data with train_data\n",
    "train_data = pd.concat([train_data, data], ignore_index=True)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Display the amount of images for training dataset",
   "id": "722dc2d2bf25005"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b4d6b65-6923-4407-883d-0ad9778ed0ad",
   "metadata": {},
   "source": [
    "# Count the number of files under each label\n",
    "file_counts = train_data['label'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of files under each label:\")\n",
    "print(file_counts)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Data preprocessing- Labeling validation data. ",
   "id": "2c09502547beee67"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6425fb35-b893-4a6d-b31f-a47be98037ef",
   "metadata": {},
   "source": [
    "# Initialize lists to store file paths and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "# Initialize an empty DataFrame for test_data\n",
    "test_data = pd.DataFrame(columns=['filepath', 'label'])\n",
    "\n",
    "# Label files under test_human as \"human\"\n",
    "for directory in test_human:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"human\")\n",
    "\n",
    "# Label files under test_ai as \"AI\"\n",
    "for directory in test_ai:\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(\"AI\")\n",
    "\n",
    "# Create a DataFrame with file paths and labels\n",
    "data = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Concatenate data with test_data\n",
    "test_data = pd.concat([test_data, data], ignore_index=True)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. Display the amount of images for validation dataset",
   "id": "bbea4f9916390238"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f904c8f3-11b6-4c35-8233-a64a7e82dcc7",
   "metadata": {},
   "source": [
    "# Display the first few rows of the test_data DataFrame\n",
    "print(test_data.head())\n",
    "\n",
    "# Count the number of files under each label\n",
    "file_counts = test_data['label'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"\\nNumber of files under each label:\")\n",
    "print(file_counts)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12. Data preprocessing- Adding data augmentation and creating training dataset. ",
   "id": "f7a855b72019d5f0"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a8c277e-fb79-4547-8d94-c1a53e9184b8",
   "metadata": {},
   "source": [
    "#Created training set with data augmentation\n",
    "training_generator = ImageDataGenerator(rescale=1./255,   # to normalize pixel value\n",
    "                                        rotation_range=7, # it will apply rotations to the image\n",
    "                                        horizontal_flip=True, # it will flip image horizontally\n",
    "                                       )\n",
    "train_dataset = training_generator.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col='filepath',  # Column containing file paths\n",
    "    y_col='label',     # Column containing labels\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',  \n",
    "    shuffle=True\n",
    ")"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 13. Data preprocessing- Adding data augmentation and creating validation dataset. ",
   "id": "9305503ceaaeebca"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17ded983-049a-4a4e-834b-f3368daa9de0",
   "metadata": {},
   "source": [
    "#Created validation set\n",
    "val_generator = ImageDataGenerator(rescale=1./255,            # Normalize the image pixel values to the range [0, 1] by scaling by 1/255\n",
    "    validation_split=0.2,      # Reserve 20% of the data for validation\n",
    "    rotation_range=20,         # Randomly rotate images by up to 20 degrees\n",
    "    width_shift_range=0.2,     # Randomly translate images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2,    # Randomly translate images vertically by up to 20% of the height\n",
    "    shear_range=0.2,           # Randomly apply shear transformations by up to 20%\n",
    "    zoom_range=0.2,            # Randomly zoom into images by up to 20%\n",
    "    horizontal_flip=True,      # Randomly flip images horizontally\n",
    "    fill_mode='nearest' )       # Fill in newly created pixels after transformations with the nearest pixel value\n",
    "val_dataset = val_generator.flow_from_dataframe(  dataframe=test_data,\n",
    "                                                    x_col='filepath',  # Column containing file paths\n",
    "                                                    y_col='label',     # Column containing labels\n",
    "                                                    target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                    batch_size = 1,    # 1 image at a time to evaluate the NN\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    shuffle = False)   # to associate the prediction with expected output"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 14. Defining VGG19 model with transfer learning and show its summary.",
   "id": "121055002d775489"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97bac3de-e382-48a1-8604-bd1a5401f32d",
   "metadata": {},
   "source": [
    "#Created network using VGG19 and transfer learning from 'ImageNet'\n",
    "network= VGG19(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "\n",
    "for layer in network.layers:\n",
    "    layer.trainable=False\n",
    "network.summary()\n",
    "\n",
    "# Added layers to the base model created by VGG16\n",
    "flatten_layer = Flatten()\n",
    "dense_layer_1 = Dense(256, activation='relu') \n",
    "dropout_1= Dropout(0.5) \n",
    "predictions = Dense(units = 1, activation='sigmoid')\n",
    "\n",
    "model = Sequential([\n",
    "   network,\n",
    "   flatten_layer,\n",
    "   dense_layer_1,\n",
    "    dropout_1,\n",
    "   predictions\n",
    "],)\n"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15. Compile the model",
   "id": "ac505c0fccd0ea5c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd13ebe0-530e-45b6-a91b-f8936f1f8899",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#Add EarlyStopping with a patience of 5 to avoid overfitting. \n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 16. Train the model :)",
   "id": "2487d8ac8369d227"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61211f74-a0dc-4e48-a8fa-a0bb29a7db51",
   "metadata": {},
   "source": [
    "#TRAINING MODEL\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=val_dataset, callbacks=[es])"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 17. Plotting the accuracy and loss functions of the epochs",
   "id": "97956edbd71afba1"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23630c1a-941e-4fc2-8e38-4fdbd6f6d85f",
   "metadata": {},
   "source": [
    "# Accuracy vs Loss\n",
    "\n",
    "# Plotting accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 0.8)  # Adjust the upper limit of the y-axis\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 18. Evaluate the trained model  ",
   "id": "4233143c58cddf2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4cb18-2e7b-48ef-9424-416c8f45a734",
   "metadata": {},
   "source": [
    "test_loss, test_acc = model.evaluate(val_dataset)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(f'Test loss: {test_loss}')"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 19. Make predictions with the trained model",
   "id": "7de2dce1345afcb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get the true labels\n",
    "true_labels = val_dataset.classes\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(val_dataset)\n",
    "predicted_labels = np.round(predictions).flatten()  # For binary classification"
   ],
   "id": "78c459e73f392725"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 20. Generate the confusion matrix to validate results and plot the information",
   "id": "f48f358df485e37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['AI', 'human'], yticklabels=['AI', 'human'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "7d635c2c6d6bf0e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
